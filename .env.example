# Singularity Agent Configuration

# Claude model to use (sonnet, opus, haiku)
# Claude Max subscription - no API key needed if logged in via `claude login`
AGENT_MODEL=sonnet

# Timezone for cron scheduling
TZ=UTC

# Embedding model for vector search (runs in separate vector service container)
# all-MiniLM-L6-v2: Fast, 384 dimensions, good quality
# all-mpnet-base-v2: Slower, 768 dimensions, better quality
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Vector service URL (auto-configured in docker-compose)
# For cloud deployment, set to your vector service endpoint
# VECTOR_SERVICE_URL=http://vector:5000

# Control Plane Configuration
CONTROL_PLANE_PORT=3001
# Optional: Set a token for API authentication (leave empty for no auth)
CONTROL_PLANE_TOKEN=

# Telegram Bot (Optional)
# Get token from @BotFather on Telegram
TELEGRAM_BOT_TOKEN=
# Your Telegram chat ID (send /start to the bot, it will show your ID)
TELEGRAM_CHAT_ID=

# TTS service URL (auto-configured in docker-compose)
# Only change if running TTS service separately
# TTS_SERVICE_URL=http://tts:8880

# Agent timeout in milliseconds (default: 30 minutes)
# Agent runs exceeding this duration will be killed and marked as failed
# AGENT_TIMEOUT_MS=1800000

# OpenAI API (for Whisper transcription)
# Get your key from https://platform.openai.com/api-keys
OPENAI_API_KEY=

# Extra directories to index for vector search (colon-separated, optional)
# These paths are inside the container â€” add matching volume mounts in docker-compose.yml
# EXTRA_SCAN_DIRS=/app/shared

# Transcription provider: openai, local, or auto (default)
# - openai: Use OpenAI Whisper API (requires OPENAI_API_KEY)
# - local: Use local GPU-accelerated Whisper container
# - auto: Try OpenAI first, fall back to local if unavailable
TRANSCRIPTION_PROVIDER=auto
