# Singularity Transcription Service
# Provides GPU-accelerated speech-to-text using faster-whisper
# Requires NVIDIA GPU with ~6GB VRAM for large-v3-turbo model

FROM nvidia/cuda:12.4.1-cudnn-runtime-ubuntu22.04

# Install Python and curl for healthcheck
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3.11 \
    python3-pip \
    curl \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Install faster-whisper with CUDA support and FastAPI
RUN pip3 install --no-cache-dir \
    faster-whisper>=1.0.0 \
    fastapi>=0.100.0 \
    uvicorn[standard]>=0.22.0 \
    python-multipart>=0.0.6

# Pre-download model during build (avoids download at runtime)
# large-v3-turbo: ~6GB VRAM, excellent quality, 6x faster than large-v3
ENV WHISPER_MODEL=large-v3-turbo
RUN python3 -c "from faster_whisper import WhisperModel; WhisperModel('large-v3-turbo', device='cpu', compute_type='int8')"

# Copy the transcription server script
COPY scripts/transcription-server.py /app/transcription-server.py

# Environment
ENV WHISPER_DEVICE=cuda

EXPOSE 5001

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:5001/health || exit 1

CMD ["python3", "transcription-server.py"]
